# 1.3H: Performance Infrastructure Enhancement

## üéØ Task Overview
**Agent**: @performance-engineer
**Duration**: 2-3 days
**Dependencies**: Phase 2 Real-time Infrastructure
**Risk Level**: Medium
**Priority**: High

## üìã Objective
Enhance the existing production-ready backend with Redis scaling, validation caching, and comprehensive performance monitoring to support multiplayer scaling requirements.

## ‚ö†Ô∏è Current Implementation Status (Needs Enhancement)

### Analysis Discovery
- ‚úÖ **Socket.io infrastructure solid** with rate limiting and health monitoring
- ‚úÖ **In-memory caching implemented** with LRU cache (1000 games, 1 hour TTL)
- ‚úÖ **Optimistic locking working** with version-based concurrency control
- ‚ö†Ô∏è **Redis adapter missing** - Socket.io limited to single server instance
- ‚ö†Ô∏è **Validation caching needed** - <50ms requirement for placement validation
- ‚ö†Ô∏è **Performance monitoring gaps** - no comprehensive dashboard

## üéØ Deliverables

### 1. Redis Integration for Horizontal Scaling
```typescript
// src/config/redis.ts
import Redis from 'ioredis';
import { createAdapter } from '@socket.io/redis-adapter';

interface RedisConfig {
  connection: {
    host: string;
    port: number;
    password?: string;
    db: number;
  };
  clustering: {
    enabled: boolean;
    nodes: Array<{ host: string; port: number }>;
  };
  performance: {
    maxRetriesPerRequest: number;
    retryDelayOnFailover: number;
    connectTimeout: number;
  };
}

class RedisManager {
  private pubClient: Redis;
  private subClient: Redis;
  private cacheClient: Redis;

  constructor(config: RedisConfig) {
    // Socket.io pub/sub clients
    this.pubClient = new Redis(config.connection);
    this.subClient = new Redis(config.connection);

    // Dedicated caching client
    this.cacheClient = new Redis({
      ...config.connection,
      db: 1, // Separate database for caching
      lazyConnect: true,
      maxRetriesPerRequest: 3
    });
  }

  getSocketAdapter() {
    return createAdapter(this.pubClient, this.subClient);
  }

  getCacheClient(): Redis {
    return this.cacheClient;
  }

  // Health check for Redis connectivity
  async healthCheck(): Promise<{ redis: boolean; latency: number }> {
    const start = Date.now();
    try {
      await this.cacheClient.ping();
      return { redis: true, latency: Date.now() - start };
    } catch (error) {
      return { redis: false, latency: -1 };
    }
  }
}
```

### 2. Validation Result Caching System
```typescript
// src/services/validationCache.ts
interface ValidationCacheService {
  // Placement validation caching
  cacheValidationResult(key: string, result: ValidationResult, ttl: number): Promise<void>;
  getValidationResult(key: string): Promise<ValidationResult | null>;

  // Formation pattern caching
  cacheFormationData(faction: Faction, data: FormationData): Promise<void>;
  getFormationData(faction: Faction): Promise<FormationData | null>;

  // Performance-critical pre-computation
  precomputeValidPositions(gameId: string): Promise<void>;
  getValidPositionsCache(gameId: string, cardId: string): Promise<Position[] | null>;
}

class ValidationCacheService implements ValidationCacheService {
  constructor(private redis: Redis) {}

  // Cache validation results for <50ms requirement
  async cacheValidationResult(key: string, result: ValidationResult, ttl: number = 300): Promise<void> {
    const cacheKey = `validation:${key}`;
    await this.redis.setex(cacheKey, ttl, JSON.stringify(result));
  }

  async getValidationResult(key: string): Promise<ValidationResult | null> {
    const cacheKey = `validation:${key}`;
    const cached = await this.redis.get(cacheKey);
    return cached ? JSON.parse(cached) : null;
  }

  // Pre-compute valid positions for performance
  async precomputeValidPositions(gameId: string): Promise<void> {
    const gameState = await gameStateService.getGameState(gameId);
    const computedPositions: Record<string, Position[]> = {};

    // Pre-compute for each card type and position
    for (const card of gameState.activeCards) {
      for (let y = 0; y < 3; y++) {
        for (let x = 0; x < 5; x++) {
          const position = { x, y };
          const validTargets = rangeCalculator.getAttackablePositions(
            card,
            position,
            gameState.board
          );

          const cacheKey = `${card.id}:${x},${y}`;
          computedPositions[cacheKey] = validTargets;
        }
      }
    }

    // Cache all computed positions
    const cacheKey = `positions:${gameId}`;
    await this.redis.setex(cacheKey, 600, JSON.stringify(computedPositions)); // 10 min TTL
  }

  // Generate cache keys for validation
  generateValidationKey(gameId: string, cardId: string, position: Position): string {
    return `${gameId}:${cardId}:${position.x},${position.y}`;
  }
}
```

### 3. Enhanced Performance Monitoring
```typescript
// src/services/performanceMonitor.ts
interface PerformanceMetrics {
  socketio: {
    activeConnections: number;
    messagesPerSecond: number;
    averageLatency: number;
    errorRate: number;
  };

  gameState: {
    activeGames: number;
    cacheHitRate: number;
    averageValidationTime: number;
    databaseQueryTime: number;
  };

  redis: {
    memoryUsage: number;
    operationsPerSecond: number;
    latency: number;
    cacheHitRate: number;
  };

  system: {
    cpuUsage: number;
    memoryUsage: number;
    uptime: number;
    errorCount: number;
  };
}

class PerformanceMonitor {
  private metrics: PerformanceMetrics;
  private intervalId: NodeJS.Timeout | null = null;

  constructor(
    private redis: Redis,
    private socketServer: Server
  ) {
    this.metrics = this.initializeMetrics();
  }

  startMonitoring(intervalMs: number = 5000): void {
    this.intervalId = setInterval(async () => {
      await this.collectMetrics();
      await this.publishMetrics();
    }, intervalMs);
  }

  async collectMetrics(): Promise<void> {
    // Socket.io metrics
    this.metrics.socketio = {
      activeConnections: this.socketServer.sockets.sockets.size,
      messagesPerSecond: await this.getSocketMessageRate(),
      averageLatency: await this.getSocketLatency(),
      errorRate: await this.getSocketErrorRate()
    };

    // Game state metrics
    this.metrics.gameState = {
      activeGames: await gameStateService.getActiveGameCount(),
      cacheHitRate: await this.getCacheHitRate(),
      averageValidationTime: await this.getAverageValidationTime(),
      databaseQueryTime: await this.getDatabaseQueryTime()
    };

    // Redis metrics
    const redisInfo = await this.redis.info();
    this.metrics.redis = this.parseRedisMetrics(redisInfo);

    // System metrics
    this.metrics.system = {
      cpuUsage: process.cpuUsage().user / 1000000, // Convert to seconds
      memoryUsage: process.memoryUsage().heapUsed / 1024 / 1024, // MB
      uptime: process.uptime(),
      errorCount: await this.getErrorCount()
    };
  }

  async publishMetrics(): Promise<void> {
    // Publish to monitoring dashboard
    await this.redis.publish('performance:metrics', JSON.stringify(this.metrics));

    // Store historical data
    await this.redis.zadd(
      'performance:history',
      Date.now(),
      JSON.stringify(this.metrics)
    );

    // Keep only last 24 hours of data
    const oneDayAgo = Date.now() - (24 * 60 * 60 * 1000);
    await this.redis.zremrangebyscore('performance:history', '-inf', oneDayAgo);
  }

  // Performance alerts
  async checkPerformanceThresholds(): Promise<void> {
    const alerts: string[] = [];

    if (this.metrics.gameState.averageValidationTime > 50) {
      alerts.push(`Validation time exceeded: ${this.metrics.gameState.averageValidationTime}ms`);
    }

    if (this.metrics.socketio.averageLatency > 100) {
      alerts.push(`Socket latency high: ${this.metrics.socketio.averageLatency}ms`);
    }

    if (this.metrics.redis.cacheHitRate < 0.8) {
      alerts.push(`Cache hit rate low: ${this.metrics.redis.cacheHitRate * 100}%`);
    }

    if (alerts.length > 0) {
      await this.sendAlerts(alerts);
    }
  }
}
```

### 4. Enhanced Socket.io Configuration
```typescript
// Update existing socketServer.ts
import { RedisManager } from '../config/redis';

export function setupSocketServer(httpServer: HttpServer, redisManager: RedisManager) {
  const io = new Server(httpServer, {
    cors: {
      origin: process.env.FRONTEND_URL || 'http://localhost:3000',
      methods: ['GET', 'POST'],
      credentials: true
    },
    transports: ['websocket', 'polling'],

    // Redis adapter for horizontal scaling
    adapter: redisManager.getSocketAdapter(),

    // Performance optimizations
    pingTimeout: 60000,
    pingInterval: 25000,
    connectTimeout: 45000,

    // Enable compression for large payloads
    compression: true,

    // Connection state recovery for reliability
    connectionStateRecovery: {
      maxDisconnectionDuration: 2 * 60 * 1000, // 2 minutes
      skipMiddlewares: true,
    }
  });

  // Enhanced connection handling with monitoring
  io.engine.on('connection_error', (err) => {
    logger.error('Socket.io connection error:', {
      code: err.code,
      message: err.message,
      context: err.context
    });
  });

  return io;
}
```

### 5. Performance-Optimized Game State Updates
```typescript
// Enhanced gameStateService.ts
class EnhancedGameStateService extends GameStateService {
  constructor(
    private redis: Redis,
    private validationCache: ValidationCacheService,
    private performanceMonitor: PerformanceMonitor
  ) {
    super();
  }

  async updateGameStateWithCaching(gameId: string, updates: Partial<GameState>): Promise<GameState> {
    const startTime = Date.now();

    try {
      // Use cached validation results when possible
      const validationKey = this.generateUpdateKey(gameId, updates);
      let validationResult = await this.validationCache.getValidationResult(validationKey);

      if (!validationResult) {
        validationResult = await this.validateGameUpdate(gameId, updates);
        await this.validationCache.cacheValidationResult(validationKey, validationResult);
      }

      if (!validationResult.valid) {
        throw new Error(validationResult.error);
      }

      // Optimistic locking with performance tracking
      const updatedState = await this.updateGameStateAtomic(gameId, updates);

      // Pre-compute next possible moves for caching
      await this.validationCache.precomputeValidPositions(gameId);

      // Track performance metrics
      const duration = Date.now() - startTime;
      this.performanceMonitor.recordOperation('game_state_update', duration);

      return updatedState;

    } catch (error) {
      this.performanceMonitor.recordError('game_state_update_failed');
      throw error;
    }
  }

  // Batch state updates for efficiency
  async updateMultipleGameStates(updates: Array<{ gameId: string; updates: Partial<GameState> }>): Promise<GameState[]> {
    const pipeline = this.redis.pipeline();
    const results: Promise<GameState>[] = [];

    for (const { gameId, updates: gameUpdates } of updates) {
      results.push(this.updateGameStateWithCaching(gameId, gameUpdates));
    }

    await pipeline.exec();
    return Promise.all(results);
  }
}
```

## ‚úÖ Acceptance Criteria

### Scaling Requirements
- [ ] Redis adapter enables multiple Socket.io server instances
- [ ] Horizontal scaling tested with 2+ server instances
- [ ] Session affinity working correctly for WebSocket connections
- [ ] Redis failover and recovery mechanisms functional

### Performance Requirements
- [ ] Validation caching achieves <50ms response time consistently
- [ ] Cache hit rate >80% for frequently accessed validation data
- [ ] Game state updates maintain <100ms performance target
- [ ] Memory usage stable under sustained load

### Monitoring Requirements
- [ ] Real-time performance dashboard functional
- [ ] Alert system triggers for performance threshold breaches
- [ ] Historical performance data collection and analysis
- [ ] Health check endpoints include Redis status

## üß™ Testing Strategy

### Load Testing
```typescript
// Performance testing with multiple server instances
describe('Performance Infrastructure', () => {
  test('should handle 1000+ concurrent connections', async () => {
    const connectionPromises = Array.from({ length: 1000 }, () =>
      createSocketConnection()
    );

    const connections = await Promise.all(connectionPromises);

    // Verify all connections successful
    expect(connections.every(conn => conn.connected)).toBe(true);

    // Verify load distributed across server instances
    const serverLoads = await getServerLoadMetrics();
    expect(serverLoads.every(load => load < 0.8)).toBe(true);
  });

  test('should achieve validation caching performance target', async () => {
    const validationTimes: number[] = [];

    for (let i = 0; i < 100; i++) {
      const start = Date.now();
      await validationCache.getValidationResult('test-key');
      validationTimes.push(Date.now() - start);
    }

    const averageTime = validationTimes.reduce((a, b) => a + b) / validationTimes.length;
    expect(averageTime).toBeLessThan(50); // <50ms requirement
  });
});
```

### Redis Integration Testing
```bash
# Test Redis failover
docker-compose exec redis redis-cli debug sleep 30
# Verify Socket.io maintains connections through Redis restart
```

## üìä Success Metrics
- **Horizontal Scaling**: Support 5+ server instances seamlessly
- **Validation Performance**: 95% of validations <50ms with caching
- **Cache Efficiency**: >80% cache hit rate for validation operations
- **Monitoring Coverage**: 100% of performance metrics tracked and alerted

## üîó Dependencies & Integration
- **Enhances**: Existing Phase 2 real-time infrastructure
- **Enables**: Production-scale multiplayer gameplay
- **Integrates With**: Current Socket.io server, game state management, monitoring systems

## üìù Notes
- **Backward Compatible**: Enhances existing implementation without breaking changes
- **Production Ready**: Focuses on scaling existing excellent architecture
- **Monitoring Critical**: Performance visibility essential for production operation
- **Redis Essential**: Required for any multi-server deployment

## üöÄ Implementation Strategy
1. **Day 1**: Redis integration and Socket.io adapter setup
2. **Day 2**: Validation caching implementation and performance optimization
3. **Day 3**: Monitoring dashboard and alert system completion

This task **ENABLES SCALING** for the excellent existing infrastructure and has **MEDIUM RISK** due to Redis integration complexity.